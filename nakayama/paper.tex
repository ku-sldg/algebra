\RequirePackage[l2tabu,orthodox]{nag}
\documentclass{article}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{minted}

\input{preamble.tex}

\begin{document}

% Mention an attempt with modules
% Formalizing algebra => crypto
% Interesting steps of the proof
% ssreflect still looks to only deal with finite/discrete objects



\title{%Formalizing 
Theoretical Commutative Algebra in Coq: \\ Nakayama's Lemma}

%\thanks{}
\date{}

%\author{}
%\address{}
%\email{}

\maketitle


\begin{abstract}
\emily[inline]{	Abstract here }
\end{abstract}


\emily[inline]{Any suggested changes to the current title are welcome.  Moreover, different fields have different standards for style, etc., so feel free to update prose/citations as appropriate. }
\emily[inline]{Add link to github for code?}


\section{Introduction}

The mathematical field of \emph{commutative algebra} stems from the study of solutions to polynomial equations, and now centers around \emph{commutative rings}, i.e., rings whose multiplication satisfies the commutative law, \emph{ideals} of these rings, and \emph{modules} over them. 
Commutative algebra has broad applications to science and technology, including in the field of robotics, and the study of the human genome.
The commutative-algebraic notion of a Gr\"obner basis, a special type of generating set for an ideal in a ring of polynomials, has become a fundamental computational tool in 
coding theory and cryptography (e.g., see  \cite{grobner-bases-cryptography}).
A implementation of Buchberger's algorithm \cite{buchberger} for determining 
Gr\'obner bases of ideals in polynomial rings has been proved correct within the proof assistant Coq \cite{the_coq_development_team_2019_3476303,thery-buchberger}, and an integrated formal development of the algorithm in Coq has also been carried out \cite{persson2001integrated} (see also \cite{grobner-type-theory}). 

Our goal is to newly formalize theoretical, rather than computational, commutative algebra in Coq.  We formally prove \emph{Nakayama's lemma} \cite{nakayama-1951, azumaya}, a fundamental theorem in the field. 
In the process of doing so,  we formalize certain algebraic structures  essential to higher-level algebra, including \emph{local rings} and \emph{modules over commutative rings}. 

The notion of a module over a ring is an extension of the linear-algebraic notion of a vector space over a field, ubiquitous in mathematics and its applications. 
Less frequently referred to as the \emph{Krull-Azumaya theorem}\footnote{Hideyuki Matsumura explains in his text \emph{Commutative Algebra} \cite{matsumura}:  ``{This simple but important lemma is due to T.\ Nakayama, G.\ Azumaya
and W.\ Krull. Priority is obscure, and although it is usually called the Lemma of Nakayama, late Prof.\  Nakayama did not like the name.''}}\,\cite{nagata}, Nakayama's lemma 
describes one way that a finitely generated module over an arbitrary commutative ring acts like a vector space over a field.  
True to the convention that ``lemma'' often refers to a result serving as a stepping stone toward another goal, Nakayama's lemma is applied widely throughout the field, and the result is typically introduced in a first graduate course in commutative algebra \cite{atiyah-macdonald, matsumura, eisenbud}.   

%It is widely applied throughout algebra. %, true to .  However, Nakayama's lemma 
%is also an important result in its own right, and can be thought of as one of the fundamental theorems of 
%commutative algebra, not unlike the fundamental theorems of calculus describing the inverse relationship between derivatives and integrals or the fundamental theorem of arithmetic that makes precise the notion of unique factorization. 
%, or the fundamental theorem of algebra (or \emph{d'Alembert's theorem}) on the roots of complex polynomials.  





\section{Mathematical basis and motivation}

In abstract algebra, the quintessential example of a \emph{commutative ring} is the collection of all integers \[\mathbb{Z} = \{ \ldots, -3, 2, -1, 0, 1, 2, 3, \ldots \}\]
One can add or multiply any two integers to obtain another, both of these binary operations satisfy the associative and commutative laws, and the distributive law governing their compatibility holds. 





In general, a ring is a set $R$ with two binary operations, which we call \emph{addition} and \emph{mutiplication}, typically denoted $\cdot$ and $+$, respectively.  Under addition, $R$ must be an abelian group, meaning that addition satisfies the associative and commutative laws, and $R$ must contain an additive identity and negatives, i.e., there exists an element $0 \in R$ such that for all $r \in R$,  $r+0 = r$  and there exists an element denoted $-r$ in $R$ for which $r + (-r) = 0$.
Moreover, multiplication must satisfy the associative law, and the distributive law on the compatibility of addition and multiplication must hold, i.e., for all $r, s, t \in R$, $r \cdot (s+t) = (r \cdot s)  + (r \cdot t)$ and $(r+s)\cdot t = (r \cdot t) + (s \cdot t)$. 

%$R$ must have an multiplicative identity, an element $1 \in R$ such that $1 \cdot r = r \cdot 1 = r$ for every $r \in R$, .  Finally, the 

The  

An \emph{ideal} of commutative ring $R$ is a subset $I$ of $R$ that is itself 
 

\begin{nak*}
Let $R$ be a commutative local ring with maximal ideal $\mathfrak{m}$, and suppose that $M$ is a finitely generated $R$-module.  If $M = \mathfrak{m} M$, then $M = 0$.
\end{nak*}


\emily[inline]{Add description of alternate statements of Nakayama.}

\section{Formalization}

We started by defining a semigroup class, which declares a binary operation to
be associative. From here, we build up through monoids, which introduce
identities, to groups, which introduce inverses. Note the double equals in
these definitions is notation for an arbitrary equivalence relation over the
group's carrier set which acts as equality.
% \begin{verbatim}
\begin{minted}{coq}
  Infix "==" := equiv (at level 60, no associativity).
  Class Semigroup := {
    semigroup_assoc:
      forall (a b c: Carrier),
        a <o> b <o> c == a <o> (b <o> c);
  }.
  Class Monoid := {
    monoid_semigroup :> Semigroup equiv op;
    monoid_ident_l:
      forall (a: Carrier), ident <o> a == a;
    monoid_ident_r:
      forall (a: Carrier), a <o> ident == a;
  }.
  Class Group := {
    group_monoid :> Monoid equiv op ident;
    group_inv_l:
      forall (a: Carrier), inv a <o> a == ident;
    group_inv_r:
      forall (a: Carrier), a <o> inv a == ident;
  }.
\end{minted}
% \end{verbatim}
The lines like \verb|monoid_semigroup :> Semigroup equiv op;| simply coerce
the monoid typeclass into a semigroup.

While we found later on that we did not need quotients, it is worth remarking
that we got quotients working rather nicely in Coq using typeclasses. An
algebraic quotient are an equivalence relation on the algebraic structure which
preserve that structure. For example, quotient groups are formed by taking a
subgroup and making every element of that subgroup equivalent to the identity.
With \texttt{P} being the predicate for the subgroup, there are two ways to
make an equivalence relation from this description.
% \begin{verbatim}
\begin{minted}{coq}
  Definition left_congru (a b: Carrier) :=
    P (inv a <o> b).
  Definition right_congru (a b: Carrier) :=
    P (a <o> inv b).
\end{minted}
% \end{verbatim}
When these two relations coincide, then we can prove that the equivalence
relation(s) actually preserve the group structure. Subgroups which have this
property are called \emph{normal subgroups}.
% \begin{verbatim}
\begin{minted}{coq}
  Let normal_subgroup_congru_coincide :=
    forall (a b: Carrier),
      left_congru op inv P a b <->
      right_congru op inv P a b.

  Theorem quotient_normal_subgroup_group:
    normal_subgroup_congru_coincide ->
    Group (left_congru op inv P) op ident inv.
\end{minted}
% \end{verbatim}

It is because of quotients that we used equivalence relations to define the
components of group structure. If we were to use the regular Leibniz equality,
this would make it very difficult to say that a quotient group is another
group. But by having the definition of a group depend upon an arbitrary
equivalence relation, we enable our theory to state that a quotient group is
simply a group with under a different equivalence. We didn't loose much as we
could still rely upon Coq's setoid rewrite tactics. Setoids are types equipped
with an equivalence relation.

Moving onwards, we then defined structures for rings, which have two binary
operations: a commutative plus \(+\) and a non-commutative times \(\cdot\), and
structures for commutative rings, where multiplication is commutative and has
an identity. Here we define \emph{ideals} which are normal subgroups under
addition and are absorbing with regards to multiplication, i.e. \(r a\) is in
the ideal whenever \(a\) is in the ideal and \(r\) is any element of the ring.
Again, we defined quotient rings but found them unnecessary in the end. Note
that should an ideal \(I\) contain a unit, an element \(x\) with a
multiplicative inverse \(x^{-1}\), then \(I\) would be the entire ring by the
absorbing property: given any element \(a\) of the ring, then \(a x^{-1}\) is
also in the ring, and \(a x^{-1} x = a 1 = a\in I\). Maximal ideals were
defined next. These are ideals that are proper subsets of the ring while having
no larger ideal except for the ring itself. Below is the definition in Coq,
which uses \texttt{P} as the predicate for the ideal.
% \begin{verbatim}
\begin{minted}{coq}
  Definition maximal_ideal :=
    exists (r: Carrier), (not (P r) /\
      forall (Q: Carrier -> Prop)
          (Q_proper: Proper (equiv ==> iff) Q)
          (Q_ideal: Ideal add zero minus mul Q),
        (forall (r: Carrier), P r -> Q r) ->
        (forall (r: Carrier), Q r) \/
          (forall (r: Carrier), Q r -> P r)).
\end{minted}
% \end{verbatim}
Almost by definition, maximal ideals can contain no units, otherwise they would
fail to be a proper subset of the ring. We could then define a local ring,
which is a ring with a single maximal ideal.
% \begin{verbatim}
\begin{minted}{coq}
  Definition local_ring :=
    exists (P: Carrier -> Prop)
        (P_proper: Proper (equiv ==> iff) P)
        (P_ideal: Ideal add zero minus mul P),
      maximal_ideal P /\
      (forall (Q: Carrier -> Prop)
          (Q_proper: Proper (equiv ==> iff) Q)
          (Q_ideal: Ideal add zero minus mul Q),
        maximal_ideal Q -> forall (r: Carrier), P r <-> Q r).
\end{minted}
% \end{verbatim}

Here we had to include an axiom that in commutative ring, any non-unit \(x\) is
contained in some maximal ideal. This was made into an axiom as the standard
mathematical argument is a proof with potentially infinitely many steps. The
standard argument goes as follows.
\begin{quote}
    Set \(I_{1}\coloneqq (x)\) to be the principal ideal for \(x\), i.e. the
    ideal generated by the single element \(x\). If \(I_{1}\) is not maximal,
    then there exists a strictly larger ideal \(I_{2}\), i.e.
    \(x\in I_{1}\subsetneq I_{2}\). If \(I_{2}\) is not maximal, then there
    exists another strictly larger ideal \(I_{3}\). Continue these arguments
    infinitely many times if necessary in order to get an infinite chain of
    ideals containing \(x\).
    \[x\in I_{1}\subsetneq I_{2}\subsetneq I_{3}\subsetneq\cdots\subsetneq R\]
    It is a simple matter to show that \(\bigcup_{k=1}^{\infty} I_{k}\) is also
    an ideal containing in \(x\). So by Zorn's lemma, there exists a maximal
    ideal in \(R\) which contains \(x\).
\end{quote}
Zorn's lemma is equivalent to the axiom of choice. So we had to add at least
one axiom here in order to proceed. By adding the axiom that we did, not only
will we encapsulate an infinite argument, but we will also avoid the need for
the axiom of choice.

Also, we used classical logic to prove that \(1 - x\) is a unit where \(x\) is
a non-unit in any local ring. The proof used the rule \(\neg\neg P\rightarrow
P\) in order to do a proof by contradiction.

The next structure defined were modules over rings which generalize vector
spaces over fields. We needed to capture the notion of linear combinations of
coefficients and module vectors. This was done by dependently typed vectors,
i.e. lists parameterized by their length. Because there is an overload of the
term ``vector'', we will use that term to refer to module vectors, and use the
term ``list'' to mean length parameterized lists. As we don't use the simpler
kind of lists, this avoids any name collisions. A finitely generated module is
like the vector space \(\mathbf{R}^{n}\) in that there are finitely many
vectors which can generate all other vectors, for \(\mathbf{R}^{n}\) one such
collection of generators are \(\mathbf{e}_{1} = \begin{pmatrix} 1 & 0 & 0 &
  \cdots & 0\end{pmatrix}^{T}\), \(\mathbf{e}_{2} = \begin{pmatrix} 0 & 1 & 0 &
  \cdots & 0\end{pmatrix}^{T}\), \textellipsis, \(\mathbf{e}_{n} =
  \begin{pmatrix} 0 & 0 & 0 & \cdots & 1\end{pmatrix}^{T}\). In our code,
\texttt{M} is the type of module elements, \texttt{R} is the type of ring
elements which act as coefficients, and \texttt{t A n} is a list whose elements
are of type \texttt{A} and whose length is \texttt{n}.
% \begin{verbatim}
\begin{minted}{coq}
  Definition finitely_generated {n: nat}(basis: t M n) :=
    forall (vector: M),
      exists (coeffs: t R n),
        vector =M= linear_combin coeffs basis.
\end{minted}
% \end{verbatim}

Next, we defined the product of an ideal \(I\) and a module \(M\), denoted as
\(I M\), which is defined to be all linear combinations of vectors from \(M\)
and coefficients from \(I\). This can be easily shown to be a submodule of
\(M\). We represented this in Coq as a predicate over \(M\).
% \begin{verbatim}
\begin{minted}{coq}
  Context (P: R -> Prop).
  Context {P_proper: Proper (Requiv ==> iff) P}.
  Context {P_ideal: Ideal Radd Rzero Rminus Rmul P}.
  
  Definition ideal_module (x: M): Prop :=
    exists (n: nat)(coeffs: t R n)(vectors: t M n),
      Forall P coeffs /\
      x =M= linear_combin Madd Mzero action coeffs vectors.
\end{minted}
% \end{verbatim}
The \verb|Forall P coeffs| ensures that every element of the coefficient list
\texttt{coeffs} satisfies the predicate \texttt{P}. From here, we can move to
stating Nakayama's lemma.

\begin{theorem}[Nakayama's lemma]
  Let \(M\) be a finitely generated module over a local ring \(R\) with maximal
  ideal \(\mathfrak{m}\). If \(\mathfrak{m} M = M\), then \(M = 0\), which is
  to say that \(M\) is the zero module which consists of exactly one element,
  that being the zero vector.
\end{theorem}

We needed a lemma before moving on to prove the main theorem which states that
for a finitely generated module \(M\) with a basis
\(b_{1}, b_{2}, \dots, b_{n}\), any element \(x\in I M\) where \(I\) is an
ideal can be written as a linear combination of the basis vectors with
coefficients coming from \(I\). The proof of this lemma is straightforward and
follows the standard, informal mathematical argument which inductively goes
through the vectors needed to generate \(x\) and shows that each vector can be
rewritten in terms of the basis vectors times elements of the ideal \(I\) as
follows.
\begin{align*}
  x & = \sum_{k=1}^{m} u_{k} a_{k} \\
    & = \sum_{k=1}^{m} u_{k} (r_{k1} b_{1} + \cdots + r_{kn} b_{n}) \\
    & = \sum_{j=1}^{n} (u_{1} r_{1j} + \cdots + u_{m} r_{mj}) b_{j}
\end{align*}
Since each \(u_{k}\) comes from the ideal \(I\), the absorbing property of
ideals guarantees that \(u_{k} r_{k j}\) is also contained in \(I\). As ideals
are also closed under addition, it follows that \(u_{1} r_{1j} + \cdots +
u_{m} r_{m j}\) are all elements of \(I\). Thus, \(x\) can be written as a
linear combination of the basis vectors with the coefficients coming from
\(I\).

For the proof of Nakayama's lemma, it too follows the standard, informal
mathematical argument. Do induction on the number of vectors needed to generate
the module \(M\). The base case where \(M\) is generated by 0 vectors is by
definition true since an empty linear combination is conventionally taken to be
the zero vector. The inductive case where \(M\) is generated by the vectors
\(b_{1}, \dots, b_{m}, b_{m+1}\). By assumption \(M = \mathfrak{m} M\) with
\(b_{1}\in M\). Then \(b_{1}\in\mathfrak{m} M\) meaning that by our lemma,
there exists a linear combination for \(b_{1}\), say
\[b_{1} = u_{1} b_{1} + \cdots + u_{m+1} b_{m+1}\]
for some \(u_{1}, \dots, u_{m+1}\in\mathfrak{m}\). Collect the \(b_{1}\) terms
on the left-hand side of the equation to get that
\[(1 - u_{1}) b_{1} = u_{2} b_{2} + \cdots + u_{m+1} b_{m+1}\text{.}\]
As mentioned when defining maximal ideals, \(\mathfrak{m}\) can only contain
non-units. Namely, \(u_{1}\) must be a non-unit. Then we had already proven
that \(1 - u_{1}\) is a unit as we are in a local ring. Let \(v_{1}\) be the
multiplicative inverse of \(1 - u_{1}\), and multiply it on both sides of the
equation.
\begin{align*}
  v_{1} (1 - u_{1}) b_{1}
    & = v_{1} u_{2} b_{2} + \cdots + v_{1} u_{m+1} b_{m+1} \\
  1 b_{1} & = \\
  b_{1} & = v_{1} u_{2} b_{2} + \cdots + v_{1} u_{m+1} b_{m+1} \\
\end{align*}
We have thus found that one of the basis vectors is not needed to generate this
module. Using the induction hypothesis, we have that \(M = 0\). Showing that
the induction hypothesis holds in Coq takes more work than in an informal
proof, but this extra work is just a lot of bookkeeping.

\bibliographystyle{plain}
\bibliography{references}
\end{document}
