\RequirePackage[l2tabu,orthodox]{nag}
\documentclass{article}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{minted}

\input{preamble.tex}

\begin{document}

% Mention an attempt with modules
% Formalizing algebra => crypto
% Interesting steps of the proof
% ssreflect still looks to only deal with finite/discrete objects



\title{Formalizing Theoretical Commutative Algebra in Coq: \\ Nakayama's Lemma}

%\thanks{}
\date{}

%\author{}
%\address{}
%\email{}

\maketitle


%\begin{abstract}
%	Abstract here
%\end{abstract}



\section{Introduction}

A number of structures from abstract algebra have been formalized using the proof assistant Coq \cite{the_coq_development_team_2019_3476303}.  
That said, for higher-level algebra, there currently appears to be a computational emphasis. 
For instance, the commutative-algebraic notion of a Gr\"obner basis, a special type of generating set for an ideal in a ring of polynomials, and which has cryptographic applications, has gathered significant attention (e.g., see \cite{thery-buchberger}).

The mathematical field of commutative algebra not only has further applications to cryptography, but also in other areas of science and technology such as data science and the study of the human genome.
Commutative algebra stems from the study of polynomial equations, and now centers around commutative rings--rings whose multiplication satisfies the commutative law, ideals of these rings, and modules over them.  It has powerful connections with other areas of theoretical mathematics including number theory and algebraic geometry.

We create a formal proof of Nakayama's lemma, a classical theorem in commutative algebra, in Coq. 
%
% ``lemma'' appearing in its name 
%\footnote{},
%
In doing so, we formalize, from scratch, certain algebraic structures that are essential to higher-level algebra, including local rings and modules over commutative rings. 
%
The notion of a module over a ring is an extension of the linear-algebraic notion of a vector space over a field, ubiquitous in mathematics and its applications. 
Nakayama's lemma exhibits one way that a finitely generated module over a commutative ring behaves like a vector space over a field.




\begin{nak*}
Let $R$ be a commutative local ring with maximal ideal $\mathfrak{m}$, and suppose that $M$ is a finitely generated $R$-module.  If $M = \mathfrak{m} M$, then $M = 0$.
\end{nak*}


\section{Mathematical Basis and Motivation}



\section{Formalization}

We started by defining a semigroup class, which declares a binary operation to
be associative. From here, we build up through monoids, which introduce
identities, to groups, which introduce inverses. Note the double equals in
these definitions is notation for an arbitrary equivalence relation over the
group's carrier set which acts as equality.
% \begin{verbatim}
\begin{minted}{coq}
  Infix "==" := equiv (at level 60, no associativity).
  Class Semigroup := {
    semigroup_assoc:
      forall (a b c: Carrier),
        a <o> b <o> c == a <o> (b <o> c);
  }.
  Class Monoid := {
    monoid_semigroup :> Semigroup equiv op;
    monoid_ident_l:
      forall (a: Carrier), ident <o> a == a;
    monoid_ident_r:
      forall (a: Carrier), a <o> ident == a;
  }.
  Class Group := {
    group_monoid :> Monoid equiv op ident;
    group_inv_l:
      forall (a: Carrier), inv a <o> a == ident;
    group_inv_r:
      forall (a: Carrier), a <o> inv a == ident;
  }.
\end{minted}
% \end{verbatim}
The lines like \verb|monoid_semigroup :> Semigroup equiv op;| simply coerce
the monoid typeclass into a semigroup.

While we found later on that we did not need quotients, it is worth remarking
that we got quotients working rather nicely in Coq using typeclasses. An
algebraic quotient are an equivalence relation on the algebraic structure which
preserve that structure. For example, quotient groups are formed by taking a
subgroup and making every element of that subgroup equivalent to the identity.
With \texttt{P} being the predicate for the subgroup, there are two ways to
make an equivalence relation from this description.
% \begin{verbatim}
\begin{minted}{coq}
  Definition left_congru (a b: Carrier) :=
    P (inv a <o> b).
  Definition right_congru (a b: Carrier) :=
    P (a <o> inv b).
\end{minted}
% \end{verbatim}
When these two relations coincide, then we can prove that the equivalence
relation(s) actually preserve the group structure. Subgroups which have this
property are called \emph{normal subgroups}.
% \begin{verbatim}
\begin{minted}{coq}
  Let normal_subgroup_congru_coincide :=
    forall (a b: Carrier),
      left_congru op inv P a b <->
      right_congru op inv P a b.

  Theorem quotient_normal_subgroup_group:
    normal_subgroup_congru_coincide ->
    Group (left_congru op inv P) op ident inv.
\end{minted}
% \end{verbatim}

It is because of quotients that we used equivalence relations to define the
components of group structure. If we were to use the regular Leibniz equality,
this would make it very difficult to say that a quotient group is another
group. But by having the definition of a group depend upon an arbitrary
equivalence relation, we enable our theory to state that a quotient group is
simply a group with under a different equivalence. We didn't loose much as we
could still rely upon Coq's setoid rewrite tactics. Setoids are types equipped
with an equivalence relation.

Moving onwards, we then defined structures for rings, which have two binary
operations: a commutative plus \(+\) and a non-commutative times \(\cdot\), and
structures for commutative rings, where multiplication is commutative and has
an identity. Here we define \emph{ideals} which are normal subgroups under
addition and are absorbing with regards to multiplication, i.e. \(r a\) is in
the ideal whenever \(a\) is in the ideal and \(r\) is any element of the ring.
Again, we defined quotient rings but found them unnecessary in the end. Note
that should an ideal \(I\) contain a unit, an element \(x\) with a
multiplicative inverse \(x^{-1}\), then \(I\) would be the entire ring by the
absorbing property: given any element \(a\) of the ring, then \(a x^{-1}\) is
also in the ring, and \(a x^{-1} x = a 1 = a\in I\). Maximal ideals were
defined next. These are ideals that are proper subsets of the ring while having
no larger ideal except for the ring itself. Below is the definition in Coq,
which uses \texttt{P} as the predicate for the ideal.
% \begin{verbatim}
\begin{minted}{coq}
  Definition maximal_ideal :=
    exists (r: Carrier), (not (P r) /\
      forall (Q: Carrier -> Prop)
          (Q_proper: Proper (equiv ==> iff) Q)
          (Q_ideal: Ideal add zero minus mul Q),
        (forall (r: Carrier), P r -> Q r) ->
        (forall (r: Carrier), Q r) \/
          (forall (r: Carrier), Q r -> P r)).
\end{minted}
% \end{verbatim}
Almost by definition, maximal ideals can contain no units, otherwise they would
fail to be a proper subset of the ring. We could then define a local ring,
which is a ring with a single maximal ideal.
% \begin{verbatim}
\begin{minted}{coq}
  Definition local_ring :=
    exists (P: Carrier -> Prop)
        (P_proper: Proper (equiv ==> iff) P)
        (P_ideal: Ideal add zero minus mul P),
      maximal_ideal P /\
      (forall (Q: Carrier -> Prop)
          (Q_proper: Proper (equiv ==> iff) Q)
          (Q_ideal: Ideal add zero minus mul Q),
        maximal_ideal Q -> forall (r: Carrier), P r <-> Q r).
\end{minted}
% \end{verbatim}

Here we had to include an axiom that in commutative ring, any non-unit \(x\) is
contained in some maximal ideal. This was made into an axiom as the standard
mathematical argument is a proof with potentially infinitely many steps. The
standard argument goes as follows.
\begin{quote}
    Set \(I_{1}\coloneqq (x)\) to be the principal ideal for \(x\), i.e. the
    ideal generated by the single element \(x\). If \(I_{1}\) is not maximal,
    then there exists a strictly larger ideal \(I_{2}\), i.e.
    \(x\in I_{1}\subsetneq I_{2}\). If \(I_{2}\) is not maximal, then there
    exists another strictly larger ideal \(I_{3}\). Continue these arguments
    infinitely many times if necessary in order to get an infinite chain of
    ideals containing \(x\).
    \[x\in I_{1}\subsetneq I_{2}\subsetneq I_{3}\subsetneq\cdots\subsetneq R\]
    It is a simple matter to show that \(\bigcup_{k=1}^{\infty} I_{k}\) is also
    an ideal containing in \(x\). So by Zorn's lemma, there exists a maximal
    ideal in \(R\) which contains \(x\).
\end{quote}
Zorn's lemma is equivalent to the axiom of choice. So we had to add at least
one axiom here in order to proceed. By adding the axiom that we did, not only
will we encapsulate an infinite argument, but we will also avoid the need for
the axiom of choice.

Also, we used classical logic to prove that \(1 - x\) is a unit where \(x\) is
a non-unit in any local ring. The proof used the rule \(\neg\neg P\rightarrow
P\) in order to do a proof by contradiction.

The next structure defined were modules over rings which generalize vector
spaces over fields. We needed to capture the notion of linear combinations of
coefficients and module vectors. This was done by dependently typed vectors,
i.e. lists parameterized by their length. Because there is an overload of the
term ``vector'', we will use that term to refer to module vectors, and use the
term ``list'' to mean length parameterized lists. As we don't use the simpler
kind of lists, this avoids any name collisions. A finitely generated module is
like the vector space \(\mathbf{R}^{n}\) in that there are finitely many
vectors which can generate all other vectors, for \(\mathbf{R}^{n}\) one such
collection of generators are \(\mathbf{e}_{1} = \begin{pmatrix} 1 & 0 & 0 &
  \cdots & 0\end{pmatrix}^{T}\), \(\mathbf{e}_{2} = \begin{pmatrix} 0 & 1 & 0 &
  \cdots & 0\end{pmatrix}^{T}\), \textellipsis, \(\mathbf{e}_{n} =
  \begin{pmatrix} 0 & 0 & 0 & \cdots & 1\end{pmatrix}^{T}\). In our code,
\texttt{M} is the type of module elements, \texttt{R} is the type of ring
elements which act as coefficients, and \texttt{t A n} is a list whose elements
are of type \texttt{A} and whose length is \texttt{n}.
% \begin{verbatim}
\begin{minted}{coq}
  Definition finitely_generated {n: nat}(basis: t M n) :=
    forall (vector: M),
      exists (coeffs: t R n),
        vector =M= linear_combin coeffs basis.
\end{minted}
% \end{verbatim}

Next, we defined the product of an ideal \(I\) and a module \(M\), denoted as
\(I M\), which is defined to be all linear combinations of vectors from \(M\)
and coefficients from \(I\). This can be easily shown to be a submodule of
\(M\). We represented this in Coq as a predicate over \(M\).
% \begin{verbatim}
\begin{minted}{coq}
  Context (P: R -> Prop).
  Context {P_proper: Proper (Requiv ==> iff) P}.
  Context {P_ideal: Ideal Radd Rzero Rminus Rmul P}.
  
  Definition ideal_module (x: M): Prop :=
    exists (n: nat)(coeffs: t R n)(vectors: t M n),
      Forall P coeffs /\
      x =M= linear_combin Madd Mzero action coeffs vectors.
\end{minted}
% \end{verbatim}
The \verb|Forall P coeffs| ensures that every element of the coefficient list
\texttt{coeffs} satisfies the predicate \texttt{P}. From here, we can move to
stating Nakayama's lemma.

\begin{theorem}[Nakayama's lemma]
  Let \(M\) be a finitely generated module over a local ring \(R\) with maximal
  ideal \(\mathfrak{m}\). If \(\mathfrak{m} M = M\), then \(M = 0\), which is
  to say that \(M\) is the zero module which consists of exactly one element,
  that being the zero vector.
\end{theorem}

We needed a lemma before moving on to prove the main theorem which states that
for a finitely generated module \(M\) with a basis
\(b_{1}, b_{2}, \dots, b_{n}\), any element \(x\in I M\) where \(I\) is an
ideal can be written as a linear combination of the basis vectors with
coefficients coming from \(I\). The proof of this lemma is straightforward and
follows the standard, informal mathematical argument which inductively goes
through the vectors needed to generate \(x\) and shows that each vector can be
rewritten in terms of the basis vectors times elements of the ideal \(I\) as
follows.
\begin{align*}
  x & = \sum_{k=1}^{m} u_{k} a_{k} \\
    & = \sum_{k=1}^{m} u_{k} (r_{k1} b_{1} + \cdots + r_{kn} b_{n}) \\
    & = \sum_{j=1}^{n} (u_{1} r_{1j} + \cdots + u_{m} r_{mj}) b_{j}
\end{align*}
Since each \(u_{k}\) comes from the ideal \(I\), the absorbing property of
ideals guarantees that \(u_{k} r_{k j}\) is also contained in \(I\). As ideals
are also closed under addition, it follows that \(u_{1} r_{1j} + \cdots +
u_{m} r_{m j}\) are all elements of \(I\). Thus, \(x\) can be written as a
linear combination of the basis vectors with the coefficients coming from
\(I\).

For the proof of Nakayama's lemma, it too follows the standard, informal
mathematical argument. Do induction on the number of vectors needed to generate
the module \(M\). The base case where \(M\) is generated by 0 vectors is by
definition true since an empty linear combination is conventionally taken to be
the zero vector. The inductive case where \(M\) is generated by the vectors
\(b_{1}, \dots, b_{m}, b_{m+1}\). By assumption \(M = \mathfrak{m} M\) with
\(b_{1}\in M\). Then \(b_{1}\in\mathfrak{m} M\) meaning that by our lemma,
there exists a linear combination for \(b_{1}\), say
\[b_{1} = u_{1} b_{1} + \cdots + u_{m+1} b_{m+1}\]
for some \(u_{1}, \dots, u_{m+1}\in\mathfrak{m}\). Collect the \(b_{1}\) terms
on the left-hand side of the equation to get that
\[(1 - u_{1}) b_{1} = u_{2} b_{2} + \cdots + u_{m+1} b_{m+1}\text{.}\]
As mentioned when defining maximal ideals, \(\mathfrak{m}\) can only contain
non-units. Namely, \(u_{1}\) must be a non-unit. Then we had already proven
that \(1 - u_{1}\) is a unit as we are in a local ring. Let \(v_{1}\) be the
multiplicative inverse of \(1 - u_{1}\), and multiply it on both sides of the
equation.
\begin{align*}
  v_{1} (1 - u_{1}) b_{1}
    & = v_{1} u_{2} b_{2} + \cdots + v_{1} u_{m+1} b_{m+1} \\
  1 b_{1} & = \\
  b_{1} & = v_{1} u_{2} b_{2} + \cdots + v_{1} u_{m+1} b_{m+1} \\
\end{align*}
We have thus found that one of the basis vectors is not needed to generate this
module. Using the induction hypothesis, we have that \(M = 0\). Showing that
the induction hypothesis holds in Coq takes more work than in an informal
proof, but this extra work is just a lot of bookkeeping.





\bibliographystyle{plain}
\bibliography{references}

\end{document}
